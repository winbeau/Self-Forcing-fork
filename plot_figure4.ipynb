{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4 复现：时序注意力可视化\n",
    "\n",
    "本 notebook 复现论文中的 Figure 4，展示自回归视频生成过程中注意力权重在帧间的分布。\n",
    "\n",
    "**论文的关键发现：**\n",
    "> \"与传统理解（认为只需保留少量初始 KV token）不同，我们的分析揭示：\n",
    "> 大多数注意力头不仅对最早的 token 分配了大量权重，还对序列中间部分分配了相当的注意力。\"\n",
    "\n",
    "**Figure 4 描述：**\n",
    "> \"Query 平均注意力展示了最后一个 chunk（第 19-21 帧）如何关注之前的 KV cache 条目（第 0-18 帧）。\n",
    "> 我们可视化了来自不同层的两个代表性注意力头——L1H1（第 1 层第 1 个头）和 L5H10（第 5 层第 10 个头）——\n",
    "> 表明注意力在整个上下文窗口中都保持显著，而不仅仅集中在初始帧。\"\n",
    "\n",
    "## 前置条件\n",
    "\n",
    "首先运行提取脚本：\n",
    "```bash\n",
    "python run_extraction_figure4.py \\\n",
    "    --config_path configs/self_forcing_dmd.yaml \\\n",
    "    --checkpoint_path checkpoints/self_forcing_dmd.pt \\\n",
    "    --output_path attention_cache_figure4.pt \\\n",
    "    --layer_indices 0 4\n",
    "```\n",
    "\n",
    "**注意**：由于 KV cache 推理模式的滑动窗口限制，捕获的数据可能只包含部分 token。\n",
    "如需完整的帧级注意力，请使用 `run_extraction_figure4.py` 脚本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# 设置绘图风格\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# 高质量 SVG 输出配置\n",
    "plt.rcParams.update({\n",
    "    'svg.fonttype': 'none',           # 使用真实字体而非路径\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['Arial', 'DejaVu Sans', 'Helvetica'],\n",
    "    'font.size': 11,\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.titlesize': 13,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'legend.fontsize': 10,\n",
    "    'figure.dpi': 150,\n",
    "    'savefig.dpi': 300,               # 高质量输出\n",
    "    'savefig.bbox': 'tight',\n",
    "    'savefig.pad_inches': 0.1,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 加载注意力权重\n",
    "\n",
    "加载由 `run_extraction_figure4.py` 生成的注意力数据缓存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载注意力权重缓存\n",
    "# 支持两种格式：\n",
    "# 1. run_extraction_figure4.py 生成的完整注意力数据（推荐）\n",
    "# 2. run_extraction.py 生成的推理模式数据\n",
    "\n",
    "CACHE_PATH = \"attention_cache_figure4.pt\"  # 优先使用完整数据\n",
    "if not Path(CACHE_PATH).exists():\n",
    "    CACHE_PATH = \"attention_cache.pt\"  # 回退到推理模式数据\n",
    "\n",
    "if not Path(CACHE_PATH).exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"未找到注意力缓存文件。请先运行以下命令之一：\\n\"\n",
    "        \"  python run_extraction_figure4.py --layer_indices 0 4\\n\"\n",
    "        \"  python run_extraction.py --layer_indices 0 1 4 5\"\n",
    "    )\n",
    "\n",
    "# 使用 weights_only=False 因为缓存可能包含 omegaconf 对象\n",
    "data = torch.load(CACHE_PATH, map_location='cpu', weights_only=False)\n",
    "\n",
    "print(f\"加载注意力数据来源: {CACHE_PATH}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  - Prompt: {data.get('prompt', 'N/A')}\")\n",
    "print(f\"  - 帧数: {data.get('num_frames', 'N/A')}\")\n",
    "print(f\"  - 每帧 token 数: {data.get('frame_seq_length', 'N/A')}\")\n",
    "print(f\"  - 每 block 帧数: {data.get('num_frame_per_block', 'N/A')}\")\n",
    "print(f\"  - 捕获的层索引: {data.get('layer_indices', 'N/A')}\")\n",
    "print(f\"  - 注意力张量数量: {len(data['attention_weights'])}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 存储供后续使用\n",
    "attention_weights = data['attention_weights']\n",
    "frame_seq_length = data.get('frame_seq_length', 1560)\n",
    "num_frames = data.get('num_frames', 21)\n",
    "num_frame_per_block = data.get('num_frame_per_block', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查捕获的注意力权重详情\n",
    "print(\"\\n捕获的注意力权重张量：\")\n",
    "print(\"=\" * 80)\n",
    "for i, w in enumerate(attention_weights):\n",
    "    layer_idx = w['layer_idx']\n",
    "    attn_shape = w['attn_weights'].shape\n",
    "    lq, lk = attn_shape[2], attn_shape[3]\n",
    "    num_heads = attn_shape[1]\n",
    "\n",
    "    # 判断数据类型\n",
    "    if 'last_block_start_frame' in w:\n",
    "        # 来自 run_extraction_figure4.py 的完整数据\n",
    "        last_start = w['last_block_start_frame']\n",
    "        q_frames = (lq // w['frame_seq_length'])\n",
    "        k_frames = lk // w['frame_seq_length']\n",
    "        data_type = f\"完整注意力 (query: 帧{last_start}-{last_start + q_frames - 1} -> key: 帧0-{k_frames - 1})\"\n",
    "    else:\n",
    "        # 来自 run_extraction.py 的推理模式数据\n",
    "        q_frames = lq // frame_seq_length if lq >= frame_seq_length else 0\n",
    "        k_frames = lk // frame_seq_length if lk >= frame_seq_length else 0\n",
    "\n",
    "        if lk == lq:\n",
    "            data_type = \"Block 内自注意力\"\n",
    "        elif lk < frame_seq_length:\n",
    "            data_type = f\"滑动窗口 KV cache ({lk} tokens)\"\n",
    "        else:\n",
    "            data_type = f\"KV cache 注意力 ({k_frames} 帧)\"\n",
    "\n",
    "    print(f\"  [{i}] Layer {layer_idx:2d}: shape={attn_shape}\")\n",
    "    print(f\"       类型: {data_type}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 检测数据格式\n",
    "is_figure4_format = any('last_block_start_frame' in w for w in attention_weights)\n",
    "print(f\"\\n数据格式: {'Figure 4 完整格式' if is_figure4_format else '推理模式格式'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 处理注意力权重\n",
    "\n",
    "注意力张量的形状通常是 `(Batch, Heads, Query_Len, Key_Len)`。\n",
    "\n",
    "对于 Figure 4，我们需要：\n",
    "1. 选择特定的层和注意力头\n",
    "2. 对 Query 维度求平均，得到\"每个 key 位置的平均注意力\"\n",
    "3. 将 token 位置映射到帧索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_frame_attention_distribution(\n",
    "    attn_data: dict,\n",
    "    frame_seq_length: int = 1560,\n",
    "    num_frames: int = 21,\n",
    "):\n",
    "    \"\"\"\n",
    "    计算 Figure 4 所需的帧间注意力分布。\n",
    "\n",
    "    对于 Figure 4，我们需要展示最后一个 chunk（query，第 19-21 帧）\n",
    "    如何关注之前的 KV cache 条目（key，第 0-18 帧）。\n",
    "\n",
    "    Args:\n",
    "        attn_data: 单个层的注意力数据字典\n",
    "        frame_seq_length: 每帧的 token 数\n",
    "        num_frames: 总帧数\n",
    "\n",
    "    Returns:\n",
    "        frame_attention: 形状为 [num_heads, num_key_frames] 的数组，\n",
    "                        展示每个 head 对每个 key 帧的平均注意力\n",
    "        key_frame_indices: key 帧的索引数组\n",
    "    \"\"\"\n",
    "    attn_weights = attn_data['attn_weights']\n",
    "    B, num_heads, lq, lk = attn_weights.shape\n",
    "\n",
    "    # 检测数据格式\n",
    "    if 'last_block_start_frame' in attn_data:\n",
    "        # Figure 4 完整格式\n",
    "        fsl = attn_data['frame_seq_length']\n",
    "        num_key_frames = lk // fsl\n",
    "    else:\n",
    "        # 推理模式格式\n",
    "        fsl = frame_seq_length\n",
    "        num_key_frames = lk // fsl if lk >= fsl else max(1, lk // (fsl // 10))\n",
    "        if num_key_frames == 0:\n",
    "            # 滑动窗口情况，使用 token 分组\n",
    "            tokens_per_group = max(1, lk // 20)\n",
    "            num_key_frames = lk // tokens_per_group\n",
    "            fsl = tokens_per_group\n",
    "\n",
    "    # 提取注意力矩阵 [B, num_heads, Lq, Lk] -> [num_heads, Lq, Lk]\n",
    "    attn = attn_weights[0].float().numpy()  # 取 batch 0\n",
    "\n",
    "    # 计算每个 head 对每个 key 帧的平均注意力\n",
    "    # 对所有 query 位置求平均，得到\"每个 key 位置平均获得多少注意力\"\n",
    "    frame_attention = np.zeros((num_heads, num_key_frames))\n",
    "\n",
    "    for head_idx in range(num_heads):\n",
    "        head_attn = attn[head_idx]  # [Lq, Lk]\n",
    "\n",
    "        # 对所有 query 位置求平均\n",
    "        avg_attn_per_key_token = head_attn.mean(axis=0)  # [Lk]\n",
    "\n",
    "        # 按 key 帧分组求和（而非平均）以得到每帧的总注意力\n",
    "        for kf in range(num_key_frames):\n",
    "            k_start = kf * fsl\n",
    "            k_end = min((kf + 1) * fsl, lk)\n",
    "            if k_end > k_start:\n",
    "                # 对帧内所有 token 的注意力求和，表示该帧获得的总注意力\n",
    "                frame_attention[head_idx, kf] = avg_attn_per_key_token[k_start:k_end].sum()\n",
    "\n",
    "    key_frame_indices = np.arange(num_key_frames)\n",
    "\n",
    "    return frame_attention, key_frame_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为所有捕获的层计算注意力分布\n",
    "layer_attention_data = {}\n",
    "\n",
    "for i, w in enumerate(attention_weights):\n",
    "    layer_idx = w['layer_idx']\n",
    "\n",
    "    frame_attention, key_frame_indices = compute_frame_attention_distribution(\n",
    "        w, frame_seq_length=frame_seq_length, num_frames=num_frames\n",
    "    )\n",
    "\n",
    "    layer_attention_data[layer_idx] = {\n",
    "        'frame_attention': frame_attention,  # [num_heads, num_frames]\n",
    "        'key_frame_indices': key_frame_indices,\n",
    "        'attn_shape': w['attn_weights'].shape,\n",
    "        'num_heads': w['attn_weights'].shape[1],\n",
    "        'is_figure4_format': 'last_block_start_frame' in w,\n",
    "    }\n",
    "\n",
    "    print(f\"Layer {layer_idx}: {len(key_frame_indices)} key 帧, {frame_attention.shape[0]} 个 head\")\n",
    "    print(f\"  注意力范围: [{frame_attention.min():.6f}, {frame_attention.max():.6f}]\")\n",
    "\n",
    "print(f\"\\n共处理 {len(layer_attention_data)} 层的注意力数据\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 绘制 Figure 4：帧间注意力分布\n",
    "\n",
    "论文中的 Figure 4 展示了两个代表性注意力头（L1H1 和 L5H10）的注意力分布。\n",
    "\n",
    "**注意**：图中所有 label 使用英文以确保兼容性和专业性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure4_paper_style(\n",
    "    layer_attention_data: dict,\n",
    "    heads_to_show: list = None,\n",
    "    save_path: str = None,\n",
    "    figsize: tuple = (14, 5),\n",
    "):\n",
    "    \"\"\"\n",
    "    按论文风格复现 Figure 4，展示帧间注意力分布。\n",
    "    图中 label 全部使用英文。\n",
    "\n",
    "    论文描述：\n",
    "    \"Query 平均注意力展示了最后一个 chunk（第 19-21 帧）如何关注之前的\n",
    "    KV cache 条目（第 0-18 帧）。我们可视化了两个代表性注意力头——\n",
    "    L1H1（第 1 层第 1 个头）和 L5H10（第 5 层第 10 个头）——\n",
    "    表明注意力在整个上下文窗口中都保持显著，而不仅仅集中在初始帧。\"\n",
    "\n",
    "    Args:\n",
    "        layer_attention_data: 层索引 -> 注意力数据的字典\n",
    "        heads_to_show: (layer_idx, head_idx, label) 元组列表\n",
    "        save_path: SVG 保存路径\n",
    "        figsize: 图像大小\n",
    "    \"\"\"\n",
    "    # 默认：展示论文中的 L1H1 和 L5H10\n",
    "    if heads_to_show is None:\n",
    "        heads_to_show = []\n",
    "        if 0 in layer_attention_data:\n",
    "            heads_to_show.append((0, 0, \"L1H1\"))\n",
    "        if 4 in layer_attention_data:\n",
    "            heads_to_show.append((4, 9, \"L5H10\"))\n",
    "        # 如果没有这些层，使用可用的层\n",
    "        if not heads_to_show:\n",
    "            for layer_idx in sorted(layer_attention_data.keys())[:2]:\n",
    "                heads_to_show.append((layer_idx, 0, f\"L{layer_idx+1}H1\"))\n",
    "\n",
    "    num_plots = len(heads_to_show)\n",
    "    if num_plots == 0:\n",
    "        print(\"No heads to display!\")\n",
    "        return None\n",
    "\n",
    "    # 使用 2 列布局\n",
    "    ncols = min(2, num_plots)\n",
    "    nrows = (num_plots + ncols - 1) // ncols\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize, squeeze=False)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # 颜色方案\n",
    "    colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#3B1F2B']\n",
    "\n",
    "    for idx, (layer_idx, head_idx, label) in enumerate(heads_to_show):\n",
    "        ax = axes[idx]\n",
    "\n",
    "        if layer_idx not in layer_attention_data:\n",
    "            ax.set_visible(False)\n",
    "            continue\n",
    "\n",
    "        data = layer_attention_data[layer_idx]\n",
    "        frame_attention = data['frame_attention']\n",
    "        key_frame_indices = data['key_frame_indices']\n",
    "\n",
    "        # 获取指定 head 的注意力\n",
    "        if head_idx >= frame_attention.shape[0]:\n",
    "            head_idx = 0\n",
    "\n",
    "        head_attn = frame_attention[head_idx]\n",
    "        color = colors[idx % len(colors)]\n",
    "\n",
    "        # 绘制柱状图\n",
    "        ax.bar(key_frame_indices, head_attn, color=color, alpha=0.7,\n",
    "               edgecolor=color, linewidth=0.5)\n",
    "\n",
    "        # 叠加折线图显示趋势\n",
    "        ax.plot(key_frame_indices, head_attn, 'o-', color=color,\n",
    "                linewidth=1.5, markersize=4, alpha=0.9)\n",
    "\n",
    "        # 英文标签\n",
    "        ax.set_xlabel('Key Frame Index', fontsize=12)\n",
    "        ax.set_ylabel('Attention Weight', fontsize=12)\n",
    "        ax.set_title(f'{label} (Layer {layer_idx+1}, Head {head_idx+1})',\n",
    "                    fontsize=13, fontweight='bold')\n",
    "\n",
    "        # 网格\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        # X 轴刻度\n",
    "        if len(key_frame_indices) <= 25:\n",
    "            ax.set_xticks(key_frame_indices)\n",
    "        else:\n",
    "            step = max(1, len(key_frame_indices) // 10)\n",
    "            ax.set_xticks(key_frame_indices[::step])\n",
    "\n",
    "        # 标注最大值\n",
    "        max_idx = np.argmax(head_attn)\n",
    "        ax.annotate(f'max@{key_frame_indices[max_idx]}',\n",
    "                   xy=(key_frame_indices[max_idx], head_attn[max_idx]),\n",
    "                   xytext=(5, 5), textcoords='offset points',\n",
    "                   fontsize=9, color='darkgreen', fontweight='bold')\n",
    "\n",
    "    # 隐藏未使用的子图\n",
    "    for idx in range(num_plots, len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "\n",
    "    # 英文标题\n",
    "    plt.suptitle(\n",
    "        'Figure 4: Frame-wise Attention Weight Distribution\\n'\n",
    "        '(Query-averaged attention from last chunk to previous frames)',\n",
    "        fontsize=14, fontweight='bold', y=1.02\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 保存为高质量 SVG\n",
    "    if save_path:\n",
    "        svg_path = save_path if save_path.endswith('.svg') else save_path.replace('.png', '.svg')\n",
    "        plt.savefig(svg_path, format='svg', bbox_inches='tight', \n",
    "                    metadata={'Creator': 'Self-Forcing Figure 4 Reproduction'})\n",
    "        print(f\"已保存到 {svg_path}\")\n",
    "\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制 Figure 4 - 论文风格，展示两个代表性 head\n",
    "# 根据论文：L1H1（第 1 层第 1 个头）和 L5H10（第 5 层第 10 个头）\n",
    "\n",
    "fig = plot_figure4_paper_style(\n",
    "    layer_attention_data,\n",
    "    heads_to_show=[\n",
    "        (0, 0, \"L1H1\"),   # Layer 1, Head 1\n",
    "        (4, 9, \"L5H10\"),  # Layer 5, Head 10\n",
    "    ],\n",
    "    save_path=\"figure4_reproduction.svg\",\n",
    "    figsize=(12, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 多头分析：热力图\n",
    "\n",
    "可视化单层所有注意力头的模式，观察它们是否表现出不同的行为。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_heads_heatmap(\n",
    "    layer_attention_data: dict,\n",
    "    layer_idx: int,\n",
    "    save_path: str = None,\n",
    "    figsize: tuple = (14, 6),\n",
    "):\n",
    "    \"\"\"\n",
    "    将单层所有 head 的注意力分布绘制为热力图。\n",
    "    图中 label 全部使用英文。\n",
    "    \"\"\"\n",
    "    if layer_idx not in layer_attention_data:\n",
    "        print(f\"Layer {layer_idx} 数据不存在！\")\n",
    "        return None\n",
    "\n",
    "    data = layer_attention_data[layer_idx]\n",
    "    frame_attention = data['frame_attention']  # [num_heads, num_frames]\n",
    "    key_frame_indices = data['key_frame_indices']\n",
    "    num_heads = frame_attention.shape[0]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # 绘制热力图\n",
    "    im = ax.imshow(frame_attention, cmap='viridis', aspect='auto', interpolation='nearest')\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label('Attention Weight', fontsize=11)\n",
    "\n",
    "    # 英文标签\n",
    "    ax.set_xlabel('Key Frame Index', fontsize=12)\n",
    "    ax.set_ylabel('Attention Head', fontsize=12)\n",
    "    ax.set_title(f'Layer {layer_idx + 1}: Attention Distribution Across All Heads',\n",
    "                fontsize=14, fontweight='bold')\n",
    "\n",
    "    # Y 轴：head 索引\n",
    "    ax.set_yticks(range(num_heads))\n",
    "    ax.set_yticklabels([f'H{i+1}' for i in range(num_heads)])\n",
    "\n",
    "    # X 轴：帧索引\n",
    "    if len(key_frame_indices) <= 25:\n",
    "        ax.set_xticks(range(len(key_frame_indices)))\n",
    "        ax.set_xticklabels(key_frame_indices)\n",
    "    else:\n",
    "        step = max(1, len(key_frame_indices) // 10)\n",
    "        ax.set_xticks(range(0, len(key_frame_indices), step))\n",
    "        ax.set_xticklabels(key_frame_indices[::step])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 保存为高质量 SVG\n",
    "    if save_path:\n",
    "        svg_path = save_path if save_path.endswith('.svg') else save_path.replace('.png', '.svg')\n",
    "        plt.savefig(svg_path, format='svg', bbox_inches='tight',\n",
    "                    metadata={'Creator': 'Self-Forcing Figure 4 Reproduction'})\n",
    "        print(f\"已保存到 {svg_path}\")\n",
    "\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制所有 head 的热力图\n",
    "# Layer 0 (L1) - 第 1 层\n",
    "if 0 in layer_attention_data:\n",
    "    fig = plot_all_heads_heatmap(\n",
    "        layer_attention_data,\n",
    "        layer_idx=0,\n",
    "        save_path=\"figure4_layer1_all_heads.svg\"\n",
    "    )\n",
    "\n",
    "# Layer 4 (L5) - 第 5 层\n",
    "if 4 in layer_attention_data:\n",
    "    fig = plot_all_heads_heatmap(\n",
    "        layer_attention_data,\n",
    "        layer_idx=4,\n",
    "        save_path=\"figure4_layer5_all_heads.svg\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 跨层注意力对比\n",
    "\n",
    "比较不同层之间 head 平均注意力分布的差异，验证论文的核心发现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_comparison(\n",
    "    layer_attention_data: dict,\n",
    "    layers_to_compare: list = None,\n",
    "    save_path: str = None,\n",
    "    figsize: tuple = (14, 5),\n",
    "):\n",
    "    \"\"\"\n",
    "    比较不同层的 head 平均注意力分布。\n",
    "    验证论文的观点：注意力分布在整个上下文窗口中，而不仅仅集中在初始帧。\n",
    "    图中 label 全部使用英文。\n",
    "    \"\"\"\n",
    "    if layers_to_compare is None:\n",
    "        layers_to_compare = sorted(layer_attention_data.keys())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(layers_to_compare)))\n",
    "\n",
    "    for idx, layer_idx in enumerate(layers_to_compare):\n",
    "        if layer_idx not in layer_attention_data:\n",
    "            continue\n",
    "\n",
    "        data = layer_attention_data[layer_idx]\n",
    "        frame_attention = data['frame_attention']\n",
    "        key_frame_indices = data['key_frame_indices']\n",
    "\n",
    "        # 对所有 head 求平均\n",
    "        mean_attention = frame_attention.mean(axis=0)\n",
    "        std_attention = frame_attention.std(axis=0)\n",
    "\n",
    "        color = colors[idx]\n",
    "        ax.plot(key_frame_indices, mean_attention, 'o-',\n",
    "               color=color, linewidth=2, markersize=5,\n",
    "               label=f'Layer {layer_idx + 1}', alpha=0.8)\n",
    "        ax.fill_between(key_frame_indices,\n",
    "                       mean_attention - std_attention,\n",
    "                       mean_attention + std_attention,\n",
    "                       color=color, alpha=0.2)\n",
    "\n",
    "    # 英文标签\n",
    "    ax.set_xlabel('Key Frame Index', fontsize=12)\n",
    "    ax.set_ylabel('Mean Attention Weight', fontsize=12)\n",
    "    ax.set_title('Cross-Layer Head-Averaged Attention Distribution',\n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='upper right', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 保存为高质量 SVG\n",
    "    if save_path:\n",
    "        svg_path = save_path if save_path.endswith('.svg') else save_path.replace('.png', '.svg')\n",
    "        plt.savefig(svg_path, format='svg', bbox_inches='tight',\n",
    "                    metadata={'Creator': 'Self-Forcing Figure 4 Reproduction'})\n",
    "        print(f\"已保存到 {svg_path}\")\n",
    "\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 跨层注意力分布对比\n",
    "fig = plot_attention_comparison(\n",
    "    layer_attention_data,\n",
    "    layers_to_compare=sorted(layer_attention_data.keys()),\n",
    "    save_path=\"figure4_layer_comparison.svg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 统计分析\n",
    "\n",
    "验证论文的核心发现：注意力分布在整个上下文窗口中，而不仅仅集中在初始帧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_statistics(layer_attention_data: dict, save_path: str = None):\n",
    "    \"\"\"\n",
    "    输出注意力分布的统计信息并可视化。\n",
    "    验证论文的核心发现：注意力分布在整个上下文窗口中。\n",
    "    图中 label 全部使用英文。\n",
    "    \"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"注意力分析摘要 (Figure 4 复现)\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # 收集统计数据\n",
    "    stats_data = []\n",
    "\n",
    "    for layer_idx in sorted(layer_attention_data.keys()):\n",
    "        data = layer_attention_data[layer_idx]\n",
    "        frame_attention = data['frame_attention']\n",
    "        key_frame_indices = data['key_frame_indices']\n",
    "        num_frames = len(key_frame_indices)\n",
    "\n",
    "        if num_frames < 3:\n",
    "            continue\n",
    "\n",
    "        # Head 平均注意力\n",
    "        mean_attn = frame_attention.mean(axis=0)\n",
    "\n",
    "        # 统计量\n",
    "        first_frame_attn = mean_attn[0]\n",
    "        last_frame_attn = mean_attn[-1]\n",
    "        middle_attn = mean_attn[1:-1].mean() if len(mean_attn) > 2 else mean_attn.mean()\n",
    "        max_frame = np.argmax(mean_attn)\n",
    "        min_frame = np.argmin(mean_attn)\n",
    "\n",
    "        stats_data.append({\n",
    "            'layer': layer_idx + 1,\n",
    "            'first': first_frame_attn,\n",
    "            'middle': middle_attn,\n",
    "            'last': last_frame_attn,\n",
    "            'max_frame': max_frame,\n",
    "            'min_frame': min_frame,\n",
    "            'ratio_first_middle': first_frame_attn / middle_attn if middle_attn > 0 else 0,\n",
    "        })\n",
    "\n",
    "        print(f\"\\nLayer {layer_idx + 1} (Key 帧数: {num_frames}):\")\n",
    "        print(f\"  首帧注意力:   {first_frame_attn:.6f}\")\n",
    "        print(f\"  中间帧注意力: {middle_attn:.6f}\")\n",
    "        print(f\"  末帧注意力:   {last_frame_attn:.6f}\")\n",
    "        print(f\"  最大注意力帧: {max_frame}\")\n",
    "        print(f\"  首帧/中间比:  {first_frame_attn/middle_attn:.2f}x\" if middle_attn > 0 else \"  首帧/中间比: N/A\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"论文的关键发现：\")\n",
    "    print(\"  '大多数注意力头不仅对最早的 token 分配了大量权重，\")\n",
    "    print(\"   还对序列中间部分分配了相当的注意力。'\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # 绘制统计可视化\n",
    "    if len(stats_data) > 0:\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "        layers = [s['layer'] for s in stats_data]\n",
    "        first_attns = [s['first'] for s in stats_data]\n",
    "        middle_attns = [s['middle'] for s in stats_data]\n",
    "        last_attns = [s['last'] for s in stats_data]\n",
    "\n",
    "        x = np.arange(len(layers))\n",
    "        width = 0.25\n",
    "\n",
    "        ax.bar(x - width, first_attns, width, label='First Frame', color='#2E86AB')\n",
    "        ax.bar(x, middle_attns, width, label='Middle Frames', color='#F18F01')\n",
    "        ax.bar(x + width, last_attns, width, label='Last Frame', color='#A23B72')\n",
    "\n",
    "        # 英文标签\n",
    "        ax.set_xlabel('Layer', fontsize=12)\n",
    "        ax.set_ylabel('Mean Attention Weight', fontsize=12)\n",
    "        ax.set_title('Attention Distribution: First vs Middle vs Last Frame',\n",
    "                    fontsize=14, fontweight='bold')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([f'L{l}' for l in layers])\n",
    "        ax.legend(fontsize=10)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # 保存为高质量 SVG\n",
    "        if save_path:\n",
    "            svg_path = save_path if save_path.endswith('.svg') else save_path.replace('.png', '.svg')\n",
    "            plt.savefig(svg_path, format='svg', bbox_inches='tight',\n",
    "                        metadata={'Creator': 'Self-Forcing Figure 4 Reproduction'})\n",
    "            print(f\"\\n已保存到 {svg_path}\")\n",
    "\n",
    "        plt.show()\n",
    "        return fig\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成统计分析和可视化\n",
    "fig = plot_attention_statistics(layer_attention_data, save_path=\"figure4_statistics.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 结果汇总\n",
    "\n",
    "列出所有生成的高质量 SVG 图像文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"FIGURE 4 复现完成\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nPrompt: {data.get('prompt', 'N/A')}\")\n",
    "print(f\"帧数: {data.get('num_frames', 'N/A')}\")\n",
    "print(f\"每 block 帧数: {data.get('num_frame_per_block', 'N/A')}\")\n",
    "print(f\"\\n捕获的层: {list(layer_attention_data.keys())}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"生成的高质量 SVG 文件（图中 label 均为英文）：\")\n",
    "print(\"-\" * 70)\n",
    "print(\"  - figure4_reproduction.svg     : 主 Figure 4 (L1H1 和 L5H10)\")\n",
    "print(\"  - figure4_layer1_all_heads.svg : Layer 1 所有 head 热力图\")\n",
    "print(\"  - figure4_layer5_all_heads.svg : Layer 5 所有 head 热力图\")\n",
    "print(\"  - figure4_layer_comparison.svg : 跨层对比\")\n",
    "print(\"  - figure4_statistics.svg       : 统计摘要\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"论文的关键观察：\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "'与传统理解（认为只需保留少量初始 KV token）不同，我们的分析揭示：\n",
    "大多数注意力头不仅对最早的 token 分配了大量权重，还对序列中间部分\n",
    "分配了相当的注意力。'\n",
    "\n",
    "这一发现表明：对于自回归视频生成，需要保留完整的上下文，而不是像\n",
    "LLM 中常用的 attention sink 机制那样只保留初始 token 和最近 token。\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 技术说明\n",
    "\n",
    "### Figure 4 结果解读\n",
    "\n",
    "**论文的关键发现：**\n",
    "> \"与传统理解（认为只需保留少量初始 KV token）不同，我们的分析揭示：\n",
    "> 大多数注意力头不仅对最早的 token 分配了大量权重，还对序列中间部分分配了相当的注意力。\"\n",
    "\n",
    "### 这意味着什么：\n",
    "\n",
    "1. **不仅仅是 Attention Sink**：与 LLM 中注意力通常集中在初始 token（attention sink 模式）不同，\n",
    "   视频扩散模型的注意力在所有帧之间分布更均匀。\n",
    "\n",
    "2. **完整上下文很重要**：对于自回归视频生成，保留完整的 KV cache 很重要——\n",
    "   不仅仅是前几帧和最近的帧。\n",
    "\n",
    "3. **层间差异**：不同层可能表现出不同的注意力模式。\n",
    "\n",
    "### 技术细节：\n",
    "\n",
    "- **Query**：最后一个 chunk（21 帧视频中的第 19-21 帧）\n",
    "- **Key**：之前的 KV cache 条目（第 0-18 帧）\n",
    "- **注意力形状**：`[B, num_heads, Lq, Lk]`\n",
    "- **每帧 token 数**：1560 tokens（60×104 / 4 patches）\n",
    "\n",
    "### SVG 输出配置：\n",
    "\n",
    "- `svg.fonttype: none` - 使用真实字体而非路径，确保文字可编辑\n",
    "- `savefig.dpi: 300` - 高分辨率输出\n",
    "- 所有图中 label 使用英文，确保跨平台兼容性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 空单元格 - notebook 结束"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv)",
   "language": "python",
   "name": "uv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
