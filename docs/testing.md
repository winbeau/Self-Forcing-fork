# æµ‹è¯•æ¨¡å—æ–‡æ¡£

æœ¬æ–‡æ¡£æè¿° `tests/` ç›®å½•ä¸‹çš„æµ‹è¯•ç»“æ„å’Œé€»è¾‘ã€‚

## ç›®å½•ç»“æ„

```
tests/
â”œâ”€â”€ __init__.py                    # åŒ…åˆå§‹åŒ–
â”œâ”€â”€ conftest.py                    # pytest é…ç½®å’Œ hooks
â”œâ”€â”€ test_extraction_logic.py       # æ³¨æ„åŠ›æå–é€»è¾‘æµ‹è¯• (ä¸»è¦)
â”œâ”€â”€ test_attention_equivalence.py  # æ³¨æ„åŠ›ç­‰ä»·æ€§æµ‹è¯•
â”œâ”€â”€ test_attention_extraction.py   # æ³¨æ„åŠ›æå–é›†æˆæµ‹è¯•
â””â”€â”€ test_flash.py                  # Flash Attention æµ‹è¯•
```

## è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰å•å…ƒæµ‹è¯•ï¼ˆè·³è¿‡ GPU æµ‹è¯•ï¼‰
python -m pytest tests -v

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
python -m pytest tests/test_extraction_logic.py -v

# è¿è¡Œ GPU é›†æˆæµ‹è¯•ï¼ˆéœ€è¦ CUDAï¼‰
python -m pytest tests --run-slow -v

# åªè¿è¡Œç‰¹å®šæµ‹è¯•ç±»
python -m pytest tests/test_extraction_logic.py::TestBlockStructure -v

# æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
python -m pytest tests -v -s
```

## conftest.py é…ç½®

### è‡ªå®šä¹‰å‘½ä»¤è¡Œé€‰é¡¹

```python
--run-slow  # è¿è¡Œæ ‡è®°ä¸º slow çš„ GPU æµ‹è¯•
```

### æµ‹è¯•æ ‡è®° (Markers)

| æ ‡è®° | è¯´æ˜ |
|-----|------|
| `@pytest.mark.slow` | æ…¢é€Ÿæµ‹è¯•ï¼Œéœ€è¦ `--run-slow` æ‰è¿è¡Œ |
| `@pytest.mark.gpu` | éœ€è¦ GPU çš„æµ‹è¯• |

### è¿›åº¦æç¤º Hooks

- **pytest_runtest_setup**: GPU æµ‹è¯•å¼€å§‹æ—¶æ˜¾ç¤ºæç¤º
- **pytest_runtest_teardown**: æ˜¾ç¤ºè€—æ—¶ >5s çš„æµ‹è¯•æ—¶é—´
- **pytest_report_teststatus**: è‡ªå®šä¹‰çŠ¶æ€ç¬¦å· (âœ“/âœ—/â—‹)

## test_extraction_logic.py

ä¸»è¦æµ‹è¯•æ–‡ä»¶ï¼ŒåŒ…å« 6 ä¸ªæµ‹è¯•ç±»ã€‚

### TestBlockStructure

æµ‹è¯• block ç»“æ„è®¡ç®—é€»è¾‘ã€‚

```python
class TestBlockStructure:
    def test_block_sizes_with_independent_first_frame(self):
        """æµ‹è¯• independent_first_frame=True æ—¶çš„ block ç»“æ„

        è¾“å…¥: num_frames=21, num_frame_per_block=3, independent_first_frame=True
        æœŸæœ›: block_sizes = [1, 3, 3, 3, 3, 3, 3], sum=19
        """

    def test_block_sizes_without_independent_first_frame(self):
        """æµ‹è¯• independent_first_frame=False æ—¶çš„ block ç»“æ„

        è¾“å…¥: num_frames=21, num_frame_per_block=3
        æœŸæœ›: block_sizes = [3, 3, 3, 3, 3, 3, 3], sum=21
        """

    def test_cumulative_k_frames(self):
        """æµ‹è¯•æ¯ä¸ª block å¯¹åº”çš„ç´¯ç§¯ K å¸§æ•°

        block_sizes = [1, 3, 3, 3, 3, 3, 3]
        æœŸæœ›ç´¯ç§¯: [1, 4, 7, 10, 13, 16, 19]
        """
```

### TestIndexMapping

æµ‹è¯•ç´¢å¼•æ˜ å°„é€»è¾‘ã€‚

```python
class TestIndexMapping:
    def test_layer_to_self_attn_index(self):
        """æµ‹è¯• layer index åˆ° self-attention è°ƒç”¨ç´¢å¼•çš„æ˜ å°„

        è§„åˆ™: layer N â†’ self-attn è°ƒç”¨ç´¢å¼• 2*N
        åŸå› : æ¯ä¸ª block æœ‰ self-attn (å¶æ•°) å’Œ cross-attn (å¥‡æ•°)

        ç¤ºä¾‹:
          layer 0  â†’ call index 0
          layer 4  â†’ call index 8
          layer 15 â†’ call index 30
          layer 29 â†’ call index 58
        """

    def test_call_index_to_block_index(self):
        """æµ‹è¯•è°ƒç”¨ç´¢å¼•å›è½¬åˆ° block ç´¢å¼•

        è§„åˆ™: call_idx // 2 = block_idx
        """
```

### TestDataFormat

æµ‹è¯•è¾“å‡ºæ•°æ®æ ¼å¼ã€‚

```python
class TestDataFormat:
    def test_output_data_structure(self):
        """æµ‹è¯•è¾“å‡ºæ•°æ®ç»“æ„

        å¿…è¦å­—æ®µ:
          - layer_index: int
          - full_frame_attention: [num_heads, num_frames, num_frames]
          - last_block_frame_attention: [num_heads, num_frames]
          - num_frames: int
          - num_heads: int
          - block_sizes: list
          - last_block_query_frames: list
        """

    def test_attention_matrix_is_causal(self):
        """æµ‹è¯•æ³¨æ„åŠ›çŸ©é˜µæ˜¯å› æœçš„ï¼ˆä¸‹ä¸‰è§’ï¼‰

        éªŒè¯: ä¸Šä¸‰è§’ (k > q) åº”è¯¥ä¸ºé›¶
        """
```

### TestAttentionCaptureMechanism

æµ‹è¯• `ATTENTION_WEIGHT_CAPTURE` å…¨å±€æ•è·æœºåˆ¶ã€‚

```python
class TestAttentionCaptureMechanism:
    def test_enable_disable(self):
        """æµ‹è¯•å¯ç”¨å’Œç¦ç”¨

        ATTENTION_WEIGHT_CAPTURE.enable(layer_indices=[0, 4], num_layers=30)
        ATTENTION_WEIGHT_CAPTURE.disable()
        """

    def test_should_capture_logic(self):
        """æµ‹è¯• should_capture é€»è¾‘

        ä½¿ç”¨æ¨¡å—åŒ–ç´¢å¼•: current_layer_idx % num_layers

        ç¤ºä¾‹ (layer_indices=[0, 8], num_layers=60):
          idx=0   â†’ 0 % 60 = 0  âœ“ æ•è·
          idx=8   â†’ 8 % 60 = 8  âœ“ æ•è·
          idx=60  â†’ 60 % 60 = 0 âœ“ æ•è·
          idx=1   â†’ 1 % 60 = 1  âœ— ä¸æ•è·
        """

    def test_effective_layer_idx(self):
        """æµ‹è¯• effective layer index è®¡ç®—

        effective = current_layer_idx % num_layers
        """
```

### TestFrameAttentionComputation

æµ‹è¯•å¸§çº§æ³¨æ„åŠ›è®¡ç®—ã€‚

```python
class TestFrameAttentionComputation:
    def test_token_to_frame_aggregation(self):
        """æµ‹è¯• token çº§æ³¨æ„åŠ›åˆ° frame çº§çš„èšåˆ

        frame_seq_length = 1560 tokens/å¸§

        èšåˆæ–¹æ³•:
          1. å¯¹æ‰€æœ‰ query tokens å–å¹³å‡
          2. å¯¹æ¯ä¸ª key frame çš„ tokens å–å¹³å‡
        """

    def test_full_matrix_assembly(self):
        """æµ‹è¯•å®Œæ•´çŸ©é˜µç»„è£…é€»è¾‘

        Block-based Causality (éä¸¥æ ¼ frame-level):
          - Block å†…æ‰€æœ‰ Q frames å¯ä»¥çœ‹åˆ°è¯¥ block ç»“æŸä¸ºæ­¢çš„æ‰€æœ‰ K frames
          - ä¾‹: Block 1 çš„ Q frames 1-3 éƒ½å¯ä»¥çœ‹åˆ° K frames 0-3

        éªŒè¯:
          - K èŒƒå›´å†…åº”è¯¥æœ‰å€¼
          - K èŒƒå›´å¤–åº”è¯¥ä¸ºé›¶
        """
```

### TestIntegrationWithGPU

GPU é›†æˆæµ‹è¯•ï¼ˆéœ€è¦ `--run-slow`ï¼‰ã€‚

```python
@pytest.mark.slow
@pytest.mark.gpu
class TestIntegrationWithGPU:
    def test_extraction_produces_valid_output(self):
        """æµ‹è¯•æå–è„šæœ¬äº§ç”Ÿæœ‰æ•ˆè¾“å‡º

        æ­¥éª¤:
          1. åŠ è½½é…ç½®å’Œ pipeline
          2. å¯ç”¨ ATTENTION_WEIGHT_CAPTURE
          3. è¿è¡Œæ¨ç†
          4. éªŒè¯æ•è·çš„æ•°æ®æ ¼å¼

        éªŒè¯:
          - æ•è·äº† attention æ•°æ®
          - æ¯ä¸ª attention æœ‰ attn_weights, k_shape, q_shape
          - attn_weights æ˜¯ 4D tensor [B, N, Lq, Lk]
        """

    def test_full_matrix_shape(self):
        """æµ‹è¯•å®Œæ•´çŸ©é˜µå½¢çŠ¶æ­£ç¡®

        æ­¥éª¤:
          1. æ•è· attention
          2. æŒ‰ K é•¿åº¦æ’åº
          3. é€ block ç»„è£…å®Œæ•´çŸ©é˜µ

        éªŒè¯:
          - å½¢çŠ¶ä¸º [num_heads, num_frames, num_frames]
          - çŸ©é˜µä¸å…¨ä¸ºé›¶
        """
```

## æµ‹è¯•é€»è¾‘è¯¦è§£

### Block ç»“æ„è®¡ç®—

```python
num_frames = 21
num_frame_per_block = 3
independent_first_frame = True

if independent_first_frame:
    # ç¬¬ä¸€å¸§ç‹¬ç«‹ï¼Œå‰©ä½™å¸§æŒ‰ block å¤§å°åˆ†ç»„
    num_blocks = (num_frames - 1) // num_frame_per_block + 1
    block_sizes = [1] + [num_frame_per_block] * ((num_frames - 1) // num_frame_per_block)
    # = [1, 3, 3, 3, 3, 3, 3], sum = 19
else:
    num_blocks = num_frames // num_frame_per_block
    block_sizes = [num_frame_per_block] * num_blocks
    # = [3, 3, 3, 3, 3, 3, 3], sum = 21
```

### Self-Attention ç´¢å¼•æ˜ å°„

æ¯ä¸ª Transformer block æœ‰ 2 æ¬¡ attention è°ƒç”¨ï¼š

```
è°ƒç”¨ 0: self-attention (layer 0)
è°ƒç”¨ 1: cross-attention (layer 0)
è°ƒç”¨ 2: self-attention (layer 1)
è°ƒç”¨ 3: cross-attention (layer 1)
...
è°ƒç”¨ 2N: self-attention (layer N)
è°ƒç”¨ 2N+1: cross-attention (layer N)
```

å› æ­¤ï¼š
```python
layer_index = 3
self_attn_call_index = 2 * layer_index  # = 6
```

### Block-based Causality

ä¸ä¼ ç»Ÿ causal attention ä¸åŒï¼š

| ä¼ ç»Ÿ Causal | Block-based Causal |
|------------|-------------------|
| frame q åªèƒ½çœ‹ k â‰¤ q | block å†…æ‰€æœ‰ q å¯ä»¥çœ‹åˆ° block ç»“æŸä¸ºæ­¢çš„ k |
| ä¸¥æ ¼ä¸‹ä¸‰è§’ | é˜¶æ¢¯çŠ¶ä¸‹ä¸‰è§’ |

```
Block 0: Q=[0],       K=[0]           (1å¸§)
Block 1: Q=[1,2,3],   K=[0,1,2,3]     (4å¸§)
Block 2: Q=[4,5,6],   K=[0,1,2,3,4,5,6] (7å¸§)
...
```

### Token-to-Frame èšåˆ

```python
frame_seq_length = 1560  # tokens per frame

# å¯¹äº Q frame qf å’Œ K frame kf
q_start = qf * frame_seq_length
q_end = (qf + 1) * frame_seq_length
k_start = kf * frame_seq_length
k_end = (kf + 1) * frame_seq_length

# å–æ‰€æœ‰ token pair çš„å¹³å‡
frame_attention[h, qf, kf] = attn_logits[h, q_start:q_end, k_start:k_end].mean()
```

## è¿›åº¦æç¤ºè¾“å‡ºç¤ºä¾‹

```
tests/test_extraction_logic.py::TestIntegrationWithGPU::test_extraction_produces_valid_output
============================================================
[GPU TEST] test_extraction_produces_valid_output
============================================================
â³ åŠ è½½æ¨¡å‹ä¸­... (é¦–æ¬¡è¿è¡Œ torch.compile éœ€è¦ 5-10 åˆ†é’Ÿ)

ğŸ“ åŠ è½½é…ç½®æ–‡ä»¶...
ğŸ”§ åˆå§‹åŒ– pipeline...
âœ“ Pipeline åˆå§‹åŒ–å®Œæˆ
ğŸš€ è¿è¡Œæ¨ç† (é¦–æ¬¡è¿è¡Œéœ€è¦ç¼–è¯‘ï¼Œè¯·è€å¿ƒç­‰å¾…)...
âœ“ æ¨ç†å®Œæˆï¼Œæ•è·äº† 7 ä¸ª attention
âœ“ é›†æˆæµ‹è¯•é€šè¿‡: æ•è·äº† 7 ä¸ª attention

â±ï¸  test_extraction_produces_valid_output è€—æ—¶: 312.5s
PASSED
```

## ç›¸å…³æ–‡ä»¶

- `tests/conftest.py` - pytest é…ç½®
- `tests/test_extraction_logic.py` - ä¸»æµ‹è¯•æ–‡ä»¶
- `wan/modules/attention.py` - ATTENTION_WEIGHT_CAPTURE å®ç°
- `experiments/run_extraction_each.py` - è¢«æµ‹è¯•çš„æå–è„šæœ¬
- `docs/attention_extraction.md` - æå–é€»è¾‘æ–‡æ¡£
